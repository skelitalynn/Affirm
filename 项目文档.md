# 显化导师 Agent 项目文档

## 项目概述
本项目旨在基于 OpenClaw + Telegram 构建一个“显化导师”Agent，特点是 Prompt 极简、长期记忆可持续、每天自动归档对话到 Notion，并提供独立后台用于配置个人画像与目标。部署环境为腾讯云，默认时区为 Asia/Shanghai (UTC+08:00)。

## 目标与非目标
目标
1. 以年为单位的长期记忆，不依赖上下文长度。
2. 每天 00:00 自动将当天对话原文写入 Notion 的父页面下的子页面。
3. 支持后台配置个人画像与目标，不依赖聊天解析。
4. 支持纯文本知识注入，并可被检索用于对话。
5. 以 OpenClaw 作为核心编排与工具调用框架。

非目标
1. 不做复杂的情绪分析或摘要处理。
2. 不做多用户、SaaS 化能力。
3. 不做前端复杂交互，仅提供最小后台配置页。

## 总体架构
组件
1. Telegram 作为对话入口。
2. OpenClaw 作为编排与工具调用层。
3. 应用层采用 Node.js + TypeScript + NestJS 实现业务逻辑与后台接口。
4. 数据访问层采用 Prisma 连接统一数据层：Postgres + pgvector。
5. LLM 默认通过 OpenAI 兼容代理（`OPENAI_BASE_URL`）调用 `MODEL_NAME`（当前为 `gpt-5.3-codex`），后续可按需切换为 Gemini 3 Flash 等其它模型。
6. Notion 作为每日对话归档载体。
7. 后台配置页用于修改用户画像与知识库。

关键设计
1. Prompt 极简，个性化与记忆依赖数据层完成。
2. 数据统一存储，向量检索与结构化查询在同一数据库完成。
3. Notion 写入为定时任务，不参与实时对话路径。

## 核心功能说明
### 1. 长期记忆
实现方式
1. 所有对话落库到 messages 表。
2. 生成向量并存储在 messages.embedding。
3. 对话时按时间窗口 + 语义相似度召回相关记忆。

优点
1. 低成本可持续扩展。
2. 召回覆盖“同义表达”的历史记忆。

限制
1. 需控制召回数量以避免上下文膨胀。
2. 超大规模时性能需调优。

### 2. 每日 Notion 归档
实现方式
1. 每天 00:00 运行定时任务。
2. 拉取前一天所有对话原文。
3. 生成 Notion 子页面，标题格式为 YYYY-MM-DD 聊天记录。
4. 页面内容为原始对话文本，不做摘要或改写。

优点
1. 实现简单，可追溯性强。
2. 易于人工回顾。

限制
1. 页面内容可能很大，后期 Notion 加载可能变慢。
2. 不利于统计与结构化检索。

### 3. 后台配置
实现方式
1. 独立小页面编辑 profiles 表。
2. 修改后立即影响对话召回和行为逻辑。
3. 通过鉴权或白名单限制访问。

优点
1. 可控、稳定、不依赖自然语言解析。
2. 适合长期维护。

限制
1. 需维护额外入口与权限。

### 4. 知识注入
实现方式
1. 用户以纯文本提交外部知识。
2. 文本分块并写入 knowledge_chunks 表。
3. 生成向量以支持语义检索。

## 数据模型（简要）
建议表
1. users
2. profiles
3. messages
4. knowledge_chunks
5. sync_jobs

字段示例
1. users: id, created_at
2. profiles: user_id, goals, status, preferences, updated_at
3. messages: id, user_id, role, content, created_at, embedding
4. knowledge_chunks: id, user_id, content, source, created_at, embedding
5. sync_jobs: id, job_type, date_key, status, created_at

## 关键流程
### 实时对话流程
1. Telegram 收到消息。
2. OpenClaw 接入并解析请求。
3. 从 profiles 获取当前画像。
4. 进行语义检索并召回历史记忆和知识片段。
5. 构造最小提示词并调用 Gemini 3 Flash。
6. 返回回复并写入 messages。

### 每日归档流程
1. 定时任务在 00:00 触发。
2. 查询前一天所有 messages。
3. 生成 Notion 子页面并写入原始对话。
4. 在 sync_jobs 标记当天已完成。

### 知识注入流程
1. 用户提交纯文本。
2. 存入 knowledge_chunks 并生成向量。
3. 后续对话按主题召回。

## 配置与部署
### 环境变量（建议）
1. `DB_URL` — Postgres 数据库连接串  
2. `TELEGRAM_BOT_TOKEN` — Telegram Bot Token  
3. `NOTION_TOKEN` — Notion 集成 Token  
4. `NOTION_PARENT_PAGE_ID` — Notion 父页面 ID  
5. `TIMEZONE=Asia/Shanghai` — 默认时区  
6. `OPENAI_API_KEY` — 通过代理访问 LLM 的 API Key（OpenAI 兼容）  
7. `OPENAI_BASE_URL` — OpenAI 兼容代理地址（当前为 `https://api.ikuncode.cc/v1`，可替换）  
8. `MODEL_NAME` — 使用的具体模型名称（当前为 `gpt-5.3-codex`）  
9. `WEBHOOK_TOKEN` — 用于校验 Telegram Webhook 的自定义 Token  

### 部署要点
1. OpenClaw Gateway 需 24/7 常驻。
2. 定时任务依赖 Gateway Cron。
3. 数据库需开启 pgvector 扩展。

## 安全与合规
1. 严格保护 Token 与数据库连接信息。
2. 后台配置页需鉴权或限制 IP。
3. 生产环境禁用调试日志输出敏感信息。

## 运行与维护
1. 数据库按月分区 messages 表提升性能。
2. 定期备份数据库与 Notion 页面。
3. 监控任务失败与重试情况。

## 成本估算
1. LLM 默认使用通过 OpenAI 兼容代理暴露的 `MODEL_NAME`（当前为 `gpt-5.3-codex`）。  
2. 成本主要来自输入与输出 token，由代理计费策略决定。  
3. 语义检索需额外 embedding 成本（可与对话模型复用同一供应商，也可拆分）。  

## 风险与应对
1. Notion 页面过大：按月分父页面或定期归档。
2. 召回过多导致上下文过长：限制 top-k。
3. 数据库膨胀：设置保留策略或冷热分层。

## 下一步计划
1. 确认 Notion 页面模板与标题规则。
2. 确认后台配置页的具体字段。
3. 完成数据库初始化与向量扩展配置。

## 术语
1. 语义检索：基于向量相似度的检索方式。
2. 父页面：Notion 中承载每日子页面的页面。
3. pgvector：Postgres 的向量扩展。

## 技术栈选型与理由
1. **后端语言与运行时：Node.js + TypeScript**
   - TypeScript 提供更好的类型安全与开发体验，便于长期维护。  
   - Node.js 生态与 OpenClaw、Telegram Bot、Notion 官方 SDK 高度兼容。  
2. **Web 框架：NestJS**
   - 模块化、依赖注入和装饰器路由非常适合本项目「bot / admin / notion / db」等清晰子模块。  
   - 自带良好的结构约束，有利于后续迭代和新功能接入。  
3. **数据库与向量存储：PostgreSQL + pgvector**
   - 支持结构化数据与向量检索统一存储，降低架构复杂度。  
   - 与 Prisma 兼容良好，便于定义 schema 与迁移。  
4. **ORM：Prisma**
   - Schema 驱动，生成类型安全的客户端，减少 SQL 手写错误。  
   - 社区成熟、文档完善，开发体验友好。  
5. **大模型与向量嵌入：OpenAI 兼容代理 + 可配置模型**
   - 当前通过 `OPENAI_BASE_URL` 调用 `MODEL_NAME=gpt-5.3-codex`，兼容 OpenAI API 协议。  
   - 在代码中通过 `llmService` / `embeddingService` 抽象，后续可以平滑切换到 Gemini 3 Flash 等其它模型。  
6. **基础设施与运维**
   - 服务器：腾讯云（Linux）  
   - 进程管理：pm2 或 systemd（生产）  
   - 自动化脚本：`daily-dev.sh` + OpenClaw Cron  

## 使用场景与用户画像
1. **核心用户画像**  
   - 已有一定自我成长/显化实践经验，希望有“长期陪伴型”AI 导师。  
   - 不关心技术细节，更看重：记得过往对话、能持续跟进目标、风格稳定。  
2. **典型使用场景**  
   - 每天通过 Telegram 与“显化导师”聊天，记录当日感受、练习、目标进展。  
   - 不定期补充自己的背景资料、目标清单、过往重要事件，希望导师“记住”。  
   - 需要在任意时间回顾某一天/某一阶段的完整对话（Notion 归档）。  
3. **使用边界**  
   - 不定位为专业心理咨询或医疗服务。  
   - 不承担多用户/多人群服务能力，默认单用户、单人格设置。  

## 功能需求（汇总视角）
### 核心功能
1. **长期对话记忆**
   - 支持以年为单位的历史对话存储与召回。  
   - 对话检索同时考虑时间窗口与语义相似度。  
2. **每日 Notion 归档**
   - 每天 00:00 自动将前一日所有对话原文写入 Notion 子页面。  
   - 页面标题统一为 `YYYY-MM-DD 聊天记录`。  
3. **后台画像与目标配置**
   - 提供最小化 Web 后台或控制台接口，支持编辑 `profiles` 中的：  
     - 个人背景信息  
     - 长期/中期/短期目标  
     - 偏好设置（语气、互动频率等）  
4. **知识注入与检索**
   - 支持以纯文本形式灌入外部知识（书摘、课程笔记等）。  
   - 支持按主题/语义在对话中检索相关知识块参与回答。  
5. **自动化开发与汇报（工程侧）**
   - 通过 `daily-dev.sh` + OpenClaw Cron 实现 7 天开发周期的自动化执行与汇报。  
   - 每天自动生成 `daily-report.md` 和追加 `dev.log`。  

### 非功能需求
1. **性能**
   - 常规单用户场景下，对话响应时间控制在 1–3 秒内（不含 LLM 排队延迟）。  
   - 向量检索 top-k 建议默认 10～30，避免上下文爆炸。  
2. **可用性**
   - 部署在单台腾讯云服务器即可稳定运行，支持 24/7。  
   - 定时任务失败有可观测日志与重试机制。  
3. **可维护性**
   - 代码按模块拆分（数据层、对话编排、Notion 同步、后台管理等）。  
   - 提供 `.env.example` 作为环境变量模板，并在文档中解释含义。  
4. **安全性**
   - 所有 Token/密钥只出现在环境变量或安全配置文件中，不写入代码库。  
   - 后台配置界面必须有鉴权（账号密码/Token/IP 白名单之一）。  

## 系统模块设计
从实现角度，将系统拆为以下模块：

1. **Telegram 接入层**
   - 负责接收 Telegram Webhook/轮询消息，进行基础校验。  
   - 标准化为内部 `Message` 对象后，交由 OpenClaw 编排层处理。  

2. **OpenClaw 编排层**
   - 将 Telegram 消息映射为工具调用与 LLM 调用序列。  
   - 关键步骤：  
     1. 读取当前用户画像（`profiles`）。  
     2. 查询近期对话与语义相似对话（`messages` + pgvector）。  
     3. 检索相关知识块（`knowledge_chunks`）。  
     4. 构造极简 Prompt + 上下文，调用 Gemini 3 Flash。  
     5. 将用户输入与模型输出写回 `messages`。  

3. **数据访问层（DAL）**
   - 封装对 Postgres 的读写（用户、画像、对话、知识块、任务状态等）。  
   - 为上层提供语义检索、时间窗口查询、分页查询等接口。  

4. **Notion 同步模块**
   - 由定时任务（OpenClaw Cron 或系统 Crontab）触发。  
   - 步骤：  
     1. 根据 `date_key` 查询前一日所有 `messages`。  
     2. 将原文拼接为 Markdown/纯文本。  
     3. 调用 Notion API 在 `NOTION_PARENT_PAGE_ID` 下创建子页面。  
     4. 将任务状态写入 `sync_jobs`（成功/失败、重试次数等）。  

5. **后台配置与知识管理模块**
   - 以最小化 Web 界面或 API 接口形式提供：  
     - `profiles` 表的增删改查。  
     - `knowledge_chunks` 文本上传、分块与删除。  
   - 可后续接入简单的登录系统（参见 `.env.example` 中的 `JWT_SECRET`）。  

6. **自动化运维模块**
   - `daily-dev.sh` 脚本负责：  
     - 每日同步代码（`git pull`）。  
     - 根据当前日期推断 Day N 任务并执行。  
     - 生成 `daily-report.md` 与更新 `dev.log`。  
     - 有变更时自动提交并 `git push`。  

## 数据库表结构设计（详细建议）
在“数据模型（简要）”基础上，给出推荐字段（实际可按技术栈调整）：

1. **users**
   - `id` (uuid / bigserial, PK)  
   - `telegram_id` (text, unique，可选)  
   - `created_at` (timestamptz, default now)  

2. **profiles**
   - `user_id` (FK → users.id, PK)  
   - `name` (text) — 用户称呼/昵称  
   - `bio` (text) — 简介/背景  
   - `goals` (jsonb/text) — 目标清单（可结构化存储）  
   - `preferences` (jsonb) — 语气、频率等偏好  
   - `status` (text) — active / paused 等  
   - `updated_at` (timestamptz)  

3. **messages**
   - `id` (bigserial, PK)  
   - `user_id` (FK → users.id)  
   - `role` (text) — user / assistant / system  
   - `content` (text) — 对话内容原文  
   - `meta` (jsonb) — 例如 Telegram message_id、对话标签等  
   - `embedding` (vector) — pgvector 存储向量  
   - `created_at` (timestamptz, index)  

4. **knowledge_chunks**
   - `id` (bigserial, PK)  
   - `user_id` (FK → users.id，可选)  
   - `title` (text) — 片段标题/来源标题  
   - `content` (text) — 文本内容  
   - `source` (text) — manual / file / url 等  
   - `tags` (text[]/jsonb)  
   - `embedding` (vector)  
   - `created_at` (timestamptz)  

5. **sync_jobs**
   - `id` (bigserial, PK)  
   - `job_type` (text) — e.g. `notion_daily_archive`  
   - `date_key` (date) — 表示归档日期  
   - `status` (text) — pending / success / failed  
   - `error` (text) — 失败原因（可选）  
   - `created_at` (timestamptz)  
   - `updated_at` (timestamptz)  

6. **推荐索引与分区**
   - `messages`：  
     - 按 `created_at` 月度分区，减少单表体积。  
     - `user_id, created_at desc` 索引用于按时间查询。  
   - `knowledge_chunks`：  
     - `user_id` 普通索引。  
   - pgvector：  
     - 对 `messages.embedding` 与 `knowledge_chunks.embedding` 建立向量索引（如 ivfflat）。  

## 接口与交互设计（概要）
> 具体路径和参数可在实现阶段补充详细 API 文档，这里给出约束和约定。

### Telegram Webhook 接口
1. **入口 URL（示例）**：`POST /webhook/telegram?token=$WEBHOOK_TOKEN`  
2. **安全约束**：  
   - 请求必须带上 `token` 且与环境变量 `WEBHOOK_TOKEN` 一致。  
   - 校验 Telegram 官方签名（可选增强）。  
3. **处理流程**：  
   - 解析 Telegram 更新，抽取 `chat_id`、`text` 等字段。  
   - 映射为内部标准消息对象，调用 OpenClaw 工作流。  

### 后台配置 API（示例）
1. `GET /admin/profile` — 获取当前用户画像。  
2. `PUT /admin/profile` — 更新画像与目标（需要鉴权）。  
3. `POST /admin/knowledge` — 上传知识文本。  
4. `GET /admin/knowledge` — 列出已存知识片段（分页）。  

### Notion 同步接口调用
1. 环境变量：  
   - `NOTION_TOKEN` — Notion 集成 Token。  
   - `NOTION_PARENT_PAGE_ID` — 父页面 ID。  
2. 主要行为：  
   - 根据日期生成标题与内容，然后调用 Notion `pages` 接口创建子页面。  
   - 失败时记录到 `sync_jobs.error`，并可设置重试策略。  

## 项目目录结构规划
结合《项目启动清单》建议的结构，可规划如下：

```bash
Affirm/
├── 项目文档.md              # 本文档
├── 项目启动清单.md          # 启动前检查 & 运维说明
├── 7天开发计划.md           # 开发里程碑与每日任务
├── daily-dev.sh            # 每日自动开发与汇报脚本
├── dev.log                 # 开发执行日志（自动生成）
├── daily-report.md         # 每日进度报告（自动生成）
├── .env.example            # 环境变量模板
├── notion/                 # Notion 相关 OpenClaw 技能
│   └── SKILL.md
├── src/                    # 源码（待创建）
│   ├── app/                # 应用入口 & 配置
│   ├── bot/                # Telegram / OpenClaw 集成
│   ├── core/               # 记忆检索、对话逻辑
│   ├── notion/             # Notion 同步模块
│   ├── admin/              # 后台管理接口/界面
│   └── db/                 # 数据访问层
├── tests/                  # 自动化测试
├── docs/                   # 额外技术文档/接口文档
└── package.json / pyproject.toml / ...  # 依赖与脚本
```

## 配置与部署（扩展说明）
在前文“配置与部署”基础上，补充更具体的约定：

1. **环境配置步骤（本地/测试环境）**
   1. 安装 PostgreSQL，并启用 pgvector 扩展。  
   2. 创建数据库 `affirm_db` 与专用用户。  
   3. 复制 `.env.example` 为 `.env`，填写真实值。  
   4. 安装依赖并初始化数据库表结构（migration 脚本）。  

2. **部署策略（生产）**
   - 单台腾讯云服务器（含应用 + 数据库）或应用/数据库拆分部署。  
   - 使用 `pm2` / `systemd` 等方式常驻后端进程。  
   - 使用 OpenClaw Gateway Cron 或系统 crontab 配置：  
     - 每日 00:00 Notion 归档任务。  
     - 每日开发任务（如仍使用 7 天计划自动推进）。  

3. **日志与文件**
   - 应用日志：按天滚动输出，推荐 JSON 格式便于集中采集。  
   - 项目级日志：`dev.log` 与 `daily-report.md` 保留最近 N 天即可。  

## 日志、监控与运维
1. **日志**
   - 等级建议：`error`, `warn`, `info`, `debug`（由 `LOG_LEVEL` 控制）。  
   - 禁止在日志中输出 Token、密钥、完整用户隐私内容。  
2. **监控**
   - 基础：CPU、内存、磁盘、Postgres 连接数。  
   - 应用层：  
     - LLM 调用失败率。  
     - Notion 同步失败率（可从 `sync_jobs` 聚合）。  
3. **告警**
   - Cron 任务连续失败 N 次触发告警。  
   - 数据库连接失败、磁盘空间不足等关键事件通过 Telegram 通知维护者。  

## 开发计划与里程碑（与 7 天计划对应）
对应《7天开发计划.md》，在此仅做概要汇总：

1. **Day 1：环境与数据库**
   - 完成 Postgres + pgvector 安装与库/表初始建模。  
   - 搭建基础项目结构与配置管理（含 `.env`）。  
2. **Day 2：核心数据层**
   - 实现 `users / profiles / messages / knowledge_chunks` 的基础 CRUD。  
   - 接入向量生成服务并存储 embedding。  
3. **Day 3：OpenClaw 集成**
   - 完成 Telegram → OpenClaw → Gemini 的完整对话闭环。  
   - 打通记忆召回路径（历史对话 + 知识片段）。  
4. **Day 4：Notion 集成**
   - 实现每日 Notion 归档功能，完成首个归档的端到端验证。  
5. **Day 5：后台配置页**
   - 实现最小可用的 Web 后台，实现画像与知识管理。  
6. **Day 6：测试与优化**
   - 编写单元测试 & 简单集成测试，优化性能与错误处理。  
7. **Day 7：部署与验收**
   - 在腾讯云部署生产实例，完成监控与备份配置，撰写项目总结。  

## 后续迭代方向（建议）
1. **多用户支持**
   - 扩展为多 User / 多 Profile 场景，按 Telegram chat_id 映射用户。  
2. **更丰富的画像维度**
   - 增加习惯、禁忌话题、能量状态等可选字段，精细化行为策略。  
3. **可视化时间线**
   - 在 Notion 或前端界面中提供时间线视图，快速回顾显化进度。  
4. **总结与提醒能力**
   - 在不改变“原文归档”的前提下，增加离线总结与周期性提醒（周/月报）。  

以上各章节与现有《项目启动清单》《7天开发计划》《.env.example》《daily-dev.sh》等文件共同构成本项目的整体规范说明，可作为后续实现与维护的统一参考。

